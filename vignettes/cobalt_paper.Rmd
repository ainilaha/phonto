---
layout: default
title: "A vignette that outlines a strategy to replicate a published analysis"
author: Laha Ale, Robert Gentleman
date: "Updated on : `r date()`"
# output: html_document
vignette: >
  %\VignetteIndexEntry{A vignette that outlines a strategy to replicate a published analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## 0. Goal

The goal of this vignette is provide some insight into how one might replicate a published analysis that was based on the NHANES data.  We have chosen the analysis presented in ``Association of blood cobalt concentrations with dyslipidemia, hypertension, and diabetes in a US population
A cross-sectional study; Hongxin Wang, MD, Feng Li, MD, Jianghua Xue, MD, Yanshuang Li, MD, Jiyu Li, MD''.  For the remainder of this vignette we will refer to this as the "Cobalt paper".
We want to emphasize that we are not, in any way attempting to critique the paper, we are simply trying to use our tools to replicate the reported results.  And even on that front, the authors had no good means to provide the sort of information that a reader would need to be able to replicate their results.  We hope that our efforts here will spur more substantial efforts to help support resources aimed at replication of research papers.  We also want to be clear, our definition of replication is very narrow - we simply want

This vignette is incomplete in many ways.  We also want to emphasize that we are not criticizing these authors, they really have no easy way to provide those details. But it is exactly that problem that we hope to address with this `phonto` package and our efforts to create a Docker container that has all of NHANES together with appropriate software tools so that others can use that as a vehicle to publish research that is more transparent.

 The Cobalt paper uses data for the years 2015-2016 and 2017-2018 which cover two NHANES cycles, the data tables we want will have the suffixes `_I` and `_J`. 

## 1. Load libs

```{r setup,warning=FALSE,message=FALSE}
# install EnWAS package via: devtools::install_github("ccb-hms/EnWAS")
library(splines)
library(ggplot2)
library(ggpubr)
library(dplyr)
library(nhanesA)
library(phonto)
library(knitr)
```


## 2. Data and Preprocessiing
In the next few sections we attempt to load data from NHANES in a manner that is consistent with the description provided in Section 2 of the Cobalt paper. Note that in Table not
all of the variables have the same number of cases. 


![Table 1 from the paper: The table is divided into five columns: overall demographics, followed by four quintiles of blood cobalt levels (Q1 to Q4). The quintiles range from ≤0.12 µg/l in Q1 to ≥0.19 µg/l in Q4. For each quintile, the number of participants, average age, gender distribution, Body Mass Index (BMI), education level, race, family poverty-income ratio, and smoking status are provided, along with standard deviations for continuous variables.](images/CobaltTable1.png)


#### 2.1) Loading the Demographic, Body Measures, and Cholesterol data into R


The authors state: 
Participants with cobalt and lipid data were included (n = 6866). Demographic characteristics of the participants, including age, gender, body mass index (BMI), education level, race, family poverty-income ratio and smoking status, were collected. Clinical data, such as blood pressure, total cholesterol (TC), low-density lipoprotein cholesterol (LDL-C), HDL-C, triglycerides (TGs), hypertension, diabetes and history of medication use, including antihypertensive drugs, hypoglycemic drugs, and lipid-lowering drugs, were extracted.

We will next present our attempt to replicate Table 1 in the Cobalt paper. This table is displayed as our Figure 1, and largely summarizes the demographic data that were used.

In the code below, we start with the variable names, which we had obtained by searching based on the variable descriptions (not shown) and restrict by the years that the authors had chosen.
While we are only going to report here on the demographic variables, we will extract all of the variables, as we are not sure how the original authors dealt with missing values.  In some cases authors only use individuals with complete data on all covariates they intend to model. But for some large data sets, such as NHANES, that can result in removing very many individuals.

We do not use LDL or triglyceride measurements as they are only available on a subset of the participants, and we would need to run two parallel analyses, which is what we presume the authors did.

```{r demo_body,warning=FALSE,message=FALSE}

##get the appropriate table names for the variables we will need
##BP
BPTabs = nhanesSearchVarName("BPQ050A", ystart="2015", ystop="2018")
LDLTabs = nhanesSearchVarName('LBDLDL',ystart="2015", ystop="2018")
##BPQ050A - currently taking meds for hypertension
##BPQ080 - told by Dr. you have high cholesterol
##BPQ100D - now taking meds for high cholesterol
##A1C
A1C = nhanesSearchVarName("LBXGH",ystart="2015", ystop="2018")
##been told by Dr. has diabetes
DrDiab = nhanesSearchVarName("DIQ010",ystart="2015", ystop="2018")
##DIQ050 - taking insulin now
##DIQ070 - taking pills for blood sugar

##HDLTabs
HDLTabs = nhanesSearchVarName("LBDHDD",ystart="2015", ystop="2018")
BMITabs = nhanesSearchVarName("BMXBMI", ystart="2015", ystop="2018")
BMXTabs = nhanesSearchVarName("BMXBMI",ystart="2015", ystop="2018")
DIQTabs = nhanesSearchVarName("DIQ010",ystart="2015", ystop="2018")
COBTabs = nhanesSearchVarName("LBXBCO",ystart="2015", ystop="2018" )
TotChol = nhanesSearchVarName("LBXTC",ystart="2015", ystop="2018" )

##set up the description of the tables, and variables within those tables we
## will use.  Then use the jointQuery function to merge the tables and to merge
##across cycles

cols = list(DEMO_I=c("RIDAGEYR","RIAGENDR","RIDRETH1","DMDEDUC2", "INDFMPIR"), 
            DEMO_J=c("RIDAGEYR","RIAGENDR","RIDRETH1","DMDEDUC2", "INDFMPIR"),
            BPQ_I=c('BPQ050A','BPQ020','BPQ080','BPQ100D'),
            BPQ_J=c('BPQ050A','BPQ020','BPQ080','BPQ100D'), 
            HDL_I=c("LBDHDD"),HDL_J=c("LBDHDD"),
            GHB_I="LBXGH",GHB_J="LBXGH",
            DIQ_I=c("DIQ010","DIQ050","DIQ070","DIQ160"),
            DIQ_J=c("DIQ010","DIQ050","DIQ070","DIQ160"), 
            BMX_I="BMXBMI", BMX_J="BMXBMI",
            TCHOL_I="LBXTC", TCHOL_J="LBXTC",
            SMQ_I=c("SMQ020","SMQ040"), SMQ_J=c("SMQ020","SMQ040"),
            BPX_I=c("BPXDI1","BPXDI2","BPXSY1","BPXSY2"), 
            BPX_J=c("BPXDI1","BPXDI2","BPXSY1","BPXSY2")
            )
var2Table = cols[c(1,3,5,7,9,11,13)]
base_df <- jointQuery(cols)


## the authors report only using individuals aged 40 and above, so we will subset to that group
base_df = base_df[base_df$RIDAGEYR>=40,]
dim(base_df)

##how many of the individuals in our cohort have complete data for all variables?
table(complete.cases(base_df))
```

 In the code above we have identifed a set of tables/questionnaires from NHANES that seem to contain the relevant variables to reproduce Table 1 in the Cobalt paper.  The tables include demographic information (`DEMO`), blood pressure and cholesterol (`BPQ`), high density lipoprotein measurements (`HDL`), Glycohemoglobin (`GHI`), Diabetes (`DIQ`), body mass (`BMX`) and total cholesterol (`TCHOL`).  We subset these tables to extract the variables we think were used in the Cobalt paper, and then merged within years and across cycles.  The result is a dataframe with `r nrow(base_df)` rows and `r `ncol(base_df)` columns.  The number of individuals is close to the 6866 the authors report using in their Table 1.
 

#### Modify the NHANES reported values to align with those used in the Paper

Now we look at some of the different variables that are going to be used in the analysis.
The authors combined the reported ethnicities of Mexican American and Other Hispanic into one group. So we will duplicate that.  They also combined the education levels into three groups, those who had no high school record, some high school, through to completion, or some education beyond high school. In the code below we carry out similar transformations of the data.


In the code chunk below we extract the smoking data, and then try to create the groupings
used in the paper.  They have three groups, non-smokers, current smokers and ex-smokers. We use the `SMQ_I` and `SMQ_J` tables. We will define non-smoker as someone who as never smoked more than 100 cigarettes (`SMQ020`), anyone who has smoked more will be either
a current smoker or an ex-smoker (`SMQ040`)



```{r}

##Education levels
base_df$DMDEDUC2 = factor(base_df$DMDEDUC2)

levels(base_df$DMDEDUC2) <- c("HS",">HS",NA,"HS","<HS",NA,">HS")
table(base_df$DMDEDUC2)

##Ethnicity

base_df$RIDRETH1 = factor(base_df$RIDRETH1)
levels(base_df$RIDRETH1) = c("Hispanic/Mexican", "Non-Hispanic Black", "Non-Hispanic White",
                          "Hispanic/Mexican", "Other")

table(base_df$RIDRETH1)

##Fixup the smoking variable to correspond to the way they defined the groups
table(base_df$SMQ020, useNA="always")
##for SMQ040 too
table(base_df$SMQ040, useNA="always")
smokingVar = ifelse(base_df$SMQ020=="No", "Non-smoker", 
                    ifelse(base_df$SMQ040=="Not at all", "Ex-smoker",
                    "Smoker"))
table(smokingVar, useNA="always")
##from the paper n=6866, Ex=1950,Non=3744,Current=1165
base_df$smokingVar = smokingVar

##Poverty level - grouped as <1, 1- 4.99, >5
  PL = cut(base_df$INDFMPIR, breaks=c(1,5), right=FALSE)
base_df$PL = PL
```
Lastly here, we will look just at the subset of demographic variables listed in Table 1.



```{r DemoSubset }

demo_sub = base_df[, c("SEQN", "RIDAGEYR","RIAGENDR", "RIDRETH1", "DMDEDUC2",  
                       "BMXBMI", "smokingVar", "PL")]

sapply(demo_sub, function(x) sum(is.na(x)))

```

## Glucose

```{r cholmeds-fixup}
cholMeds = base_df$BPQ100D
table(cholMeds, useNA="always")

cholMeds[base_df$BPQ080=="No"] = "No"
cholMeds[cholMeds=="Don't know"] = NA
cholMeds = factor(cholMeds)
table(cholMeds,useNA="always")
base_df$cholMeds=cholMeds

##now fixup the oral meds for diabetes
##not counting insulin right now...might need it
dontskip = base_df$DIQ010 == "Yes" | base_df$DIQ010 == "Borderline" | base_df$DIQ160 == "Yes"
hypoglycemicMeds = base_df$DIQ070
hypoglycemicMeds[!dontskip] = "No" 
hypoglycemicMeds = factor(hypoglycemicMeds,levels=c("Yes", "No", "Don't know","Refused"), labels=c("Yes", "No",NA,NA))
table(hypoglycemicMeds,useNA="always")
base_df$hypoglycemicMeds = hypoglycemicMeds
```

Then fixup glucose

```{r Glucose, warning=FALSE, message=FALSE}
##fasting glucose
Fastgluc = nhanesSearchVarName("LBXGLU", ystart="2015", ystop="2018")
glucTab = unionQuery(list(GLU_I="LBXGLU", GLU_J="LBXGLU"))
base_df = merge(base_df, glucTab, all.x=TRUE)
```
The two variables that require additional lab work are LDLs and cobalt levels. As a result they were done on a much smaller set of people.  So instead of loading them simultaneously we extract them below and then use the `merge`
```{r load TRIGLY and CRCO}
ldlTab = unionQuery(list(TRIGLY_I=c("LBXTR","LBDLDL"),TRIGLY_J=c("LBXTR","LBDLDL"))) 
dim(ldlTab)
cobaltTab = unionQuery(list(CRCO_I="LBXBCO", CRCO_J="LBXBCO"))
dim(cobaltTab)
var2Table = c(var2Table, list("TRIGLY_I"=c("LBXTR","LBDLDL"), CRCO_I="LBXBCO"))
##we merge keeping as many records as we can, the all.x argument is important
bdf = merge(base_df, ldlTab, all.x=TRUE)
base_df = merge(bdf, cobaltTab, all.x=TRUE)
dim(base_df)
```
If we were to remove all records with missing values at this point we would be left with a very small number of cases.  So we will try to be careful not to loose too many data points.

#### 2.2) Blood Pressure Data

Both systolic (BPXS) and diastolic (BPXD) measurements were taken twice, on two separate occassions.  The authors of the Cobalt paper do not specify how they dealt this, did they use the first, the second, an average of the two?  How did they deal with individuals that did not show up for their second measurement?  We will use the average of these two measurements for individuals with two measurements, and in the case where only one measurement is available we will use it. The authors of the Cobalt paper don't specify which values they used, so this is one of the places where our analysis may differ from theirs.

We will just extract the data for the 2015-2016 and 2017-2018 years. We combine these into a single dataframe and then compute the average, for those who have two measurements.

```{r extract_data, warning=FALSE, message=FALSE}
##fixup the blood pressure data - using averages
# Average the the first and second reads
# taking some care to keep one measurement if the other is missing
base_df$DIASTOLIC <- rowMeans(base_df[, c("BPXDI1", "BPXDI2")], na.rm=TRUE)
base_df$DIASTOLIC[is.na(base_df$BPXDI1) & is.na(base_df$BPXDI2)] = NA
base_df$SYSTOLIC <- rowMeans(base_df[, c("BPXSY1", "BPXSY2")], na.rm=TRUE)
base_df$SYSTOLIC[is.na(base_df$BPXSY1) & is.na(base_df$BPXSY2)] = NA

```
  In our analysis we can then look at the average of the measurements across the two different time points as a way to estimate the actual blood pressure for each participant.



Now you have a dataframe with the data, but you will need to better understand the variables, exposures and responses.  To help with that we have created some tools, based on related work in the UK Biobank called PHESANT  (cite PHESANT)).  The process takes each variable (column)
and reports what type of data it is, continuous or multi-level (ie factors). We report the number of levels. Some numeric quantities are reported such as the ratio of unique values to the length of vector, the proportion of zeros, and the proportion of missing values. NHANES has chosen to store categorical data types (ordered or unordered) as integers. For example, education level, `DMDEDUC2` is identified as `Multilevel-8 `.  You can learn more about the details of the NHANES data in the Quick Start Vignette (cite quick start).

We also need to address some issues around the hypertension variables. Particpants were asked (BPQ020) whether they had ever been told by a doctor or health care professional that they had high blood pressure.  The survey was designed to then skip over a number of questions about their hypertension if they said they did not have hypertension. However this then introduces missing values in the question BPQ050A, which was whether or not they were currently taking a prescription for hypertension. Presumably only people who had been told by their doctor they have hypertension would be taking a perscription and we will need to manually adjust the data so that these are answered No, rather than missing.


```{r}
##
## fixup the data for a skipped question
hypertensiveMeds = base_df$BPQ050A
hypertensiveMeds[base_df$BPQ020=="No"] = "No"
hypertensiveMeds[base_df$BPQ040A=="No"] = "No"

base_df$BPQ050A = hypertensiveMeds

```
At this point we have `r nrow(data)` individuals left. 

## Replication of Table 1
Table 1 provides some basic summaries of the demographic data. We will create a 
temporary subset of the data that uses only the complete cases.

```{r, message=FALSE, warning=FALSE}
pcobalt = ifelse(base_df$LBXBCO <= 0.12, "<=0.12", 
                ifelse(base_df$LBXBCO >= 0.13 & base_df$LBXBCO <= 0.14, "0.13-0.14",
                  ifelse(base_df$LBXBCO >= 0.15 & base_df$LBXBCO <= 0.18, "0.15-0.18",
                         ifelse(base_df$LBXBCO >= 0.19, ">=1.9",
                         NA)  )))
##make it an ordered factor 
pcob = factor(pcobalt, levels=c("<=0.12","0.13-0.14", "0.15-0.18",">=1.9"), ordered=TRUE)
base_df$pcobalt = pcob
table(pcob, useNA="always")
AgeGp = base_df |> group_by(pcobalt) |> summarise(mean=mean(RIDAGEYR,na.rm=TRUE),SD=sd(RIDAGEYR,na.rm=TRUE))

```

## 2.4 Definitions
Here we implement the definitions from Section 3.1 of the Cobalt paper. For hypertension they described using reported systolic and diastolic blood pressure measurements as well as self-reported statements regarding whether a physician had ever told them that they have high blood pressure.  

Note that it is unclear whether the authors used averaged over 2 measurements for the systolic and diastolic blood pressure measurements. Still, we use average them because it would give us more accurate blood pressure measurements.

One might also look at the use of prescribed hypertensives, as these will modulate the systolic and diastolic measures.  Data on self-report come from the BPQ tables in NHANES.
https://wwwn.cdc.gov/nchs/nhanes/2011-2012/BPQ_G.htm

```{r RiskFactors,warning=FALSE,message=FALSE}
# "Hypertension was defined as systolic blood pressure (SBP) ≥140 mm Hg, diastolic blood pressure ≥90mm Hg, or the use of antihypertensive medication. "
base_df$hypertension <- base_df$DIASTOLIC >= 90 | base_df$SYSTOLIC >= 140 |  base_df$BPQ050A=="Yes"
barplot(table(base_df$hypertension))
```
```{r Diabetes, warning=FALSE, message=FALSE}
base_df$diabetes = base_df$DIQ010 == "Yes" | base_df$LBXGLU > 110 | base_df$LBXGH > 6.5
barplot(table(base_df$diabetes))

base_df$HighLDL = base_df$LBDLDL > 130
barplot(table(base_df$HighLDL))
 
base_df$LowHDL = (base_df$RIAGENDR=="Male" & base_df$LBDHDD < 40) |    (base_df$RIAGENDR=="Female" & base_df$LBDHDD < 50) 
barplot(table(base_df$LowHDL))

```
Now lets define the elevated total cholesterol variable.

```{r Dyslipidemia}
elevatedTC = base_df$LBXTC>200
base_df$elevatedTC = elevatedTC
```

Note that some of our groupings are very similar to those reported in the Cobalt paper, but some, notably Elevated LDLs are quite different. This discrepency should be explored (it may have to do with incorrect subsetting by age).
## 2.5 Compare with Table-2
```{r, message=FALSE,warning=FALSE}

DBP = base_df |> group_by(pcobalt) |> summarise(mean=mean(DIASTOLIC, na.rm=TRUE),SD=sd(DIASTOLIC,na.rm=TRUE))
DBP$stat = paste(round(DBP$mean,1),"±",round(DBP$SD,1))
DBPmn = mean(base_df$DIASTOLIC, na.rm=TRUE)
DBPsd = sd(base_df$DIASTOLIC, na.rm=TRUE)

SBP = base_df |> group_by(pcobalt) |> summarise(mean=mean(SYSTOLIC,na.rm=TRUE),SD=sd(SYSTOLIC, na.rm=TRUE))
SBP$stat = paste(round(SBP$mean,1),"±",round(SBP$SD,1))
SBPmn = mean(base_df$SYSTOLIC, na.rm=TRUE)
SBPsd = sd(base_df$SYSTOLIC, na.rm=TRUE)

dbp_t = t(DBP)
colnames(dbp_t) = DBP$pcobalt

sbp_t = t(SBP)
colnames(sbp_t) = SBP$pcobalt

table2 = rbind(sbp_t["stat",],dbp_t["stat",])
table2 = table2[,c("<=0.12","0.13-0.14","0.15-0.18",">=1.9")]
table2 = cbind("Blood Pressures"=c("SBP (mm Hg), mean±SD","DBP (mm Hg), mean±SD"),table2)
```
It shows the number we have is not exactly the same as the one in the table-2 in the paper. The authors did not use the average of two reads of the blood pressure measurements.

```{r, message=FALSE,warning=FALSE}
library(kableExtra)
kbl(table2) |>
  kable_classic() |>
  add_header_above(c(" " = 1, "Cobalt Quartiles (ug/L)" = 4))

```


The authors don't seem to explore the relationship between taking medications (eg. insulin and oral hypoglycemic drugs) and disease (eg diabetes, or fasting glucose rate).  For hypertension, hypoglycemia and dislipemia it seems like these would be interesting relationships to explore.


## 3.Regression Models

In Section 3.2 of the Cobalt paper the authors describe their use of binary logistic regression models.  They use dyslipidemia as the outcome and adjust for age, sex and BMI (their model 1).  They split cobalt levels into the groupings described above and then fit logistic models that were linear in the covariates.  Here we provide the tools to replicate that analysis and also explore the use of regression splines to fit the continuous variables in the model, namely age, BMI and cobalt levels.

In the following section, we run the logistic regression models as generalized linear models (GLMs). In the models, the outcome of the hypertension indicator and the adjusted variables are age (RIDAGEYR), gender (RIAGENDR), BMI (BMXBMI), education (DMDEDUC2), and ethnicity (RIDRETH1). The first GLM is with linear terms, and the second GLM also adds terms linearly together but applies a natural spline to the continuous variables.      

```{r Model1, warnings=FALSE, message=FALSE}
subSet = base_df[, c("hypertension","RIDAGEYR", "RIAGENDR", "BMXBMI","DMDEDUC2", "RIDRETH1")]
subSet = na.omit(subSet)

lm_logit <- glm(hypertension ~ RIDAGEYR + RIAGENDR + BMXBMI+DMDEDUC2+RIDRETH1, data = subSet, family = "binomial",na.action=na.omit)

##spline covariates
ns_logit <- glm(hypertension ~ ns(RIDAGEYR,df=7)+RIAGENDR + ns(BMXBMI,df=7) + DMDEDUC2 + RIDRETH1, 
                   data = subSet, family = "binomial",na.action=na.omit)

```
###Model 2
In the code below we fit model two.
```{r QA/QC, warnings=FALSE, message=FALSE}
## glm linear in the covariates
##we first want to reduce to those that have values for these covariates
subSet = base_df[, c("hypertension","RIDAGEYR", "RIAGENDR", "BMXBMI","DMDEDUC2", "RIDRETH1")]
subSet = na.omit(subSet)

lm_logit <- glm(hypertension ~ RIDAGEYR + RIAGENDR + BMXBMI+DMDEDUC2+RIDRETH1, data = subSet, family = "binomial",na.action=na.omit)

##spline covariates
ns_logit <- glm(hypertension ~ ns(RIDAGEYR,df=7)+RIAGENDR + ns(BMXBMI,df=7) + DMDEDUC2 + RIDRETH1, 
                   data = subSet, family = "binomial",na.action=na.omit)

```
### 3.1) QA/QC
```{r}
# library(pROC)
library(plotROC)
test = data_frame(hypertension=subSet$hypertension,lm=lm_logit$fitted.values,   ns=ns_logit$fitted.values)
longtest <- reshape2::melt(test,id.vars="hypertension")
colnames(longtest) = c('hypertension','model','value')
ggplot(longtest, aes(d = as.numeric(hypertension), m = value, color = model))+ geom_abline()+ geom_roc(size = 1.25) + style_roc()

# plot(roc(base_df$hypertension,
#                    fitted(lm_logit)),
#                print.auc = T, 
#                col = "red")
# 
# plot(roc(base_df$hypertension,
#                    fitted(ns_logit)),
#                print.auc = T, 
#                col = "blue", 
#                add = T)
```

```{r}
# Age
df_age_fitt = list("Binned Data"=make_bins(x=subSet$RIDAGEYR,y=as.numeric(subSet$hypertension),nbin=600),
                  "Linear"=make_bins(x=subSet$RIDAGEYR,y=lm_logit$fitted.values,nbin=600),
                  "Spline"=make_bins(x=subSet$RIDAGEYR,y=ns_logit$fitted.values,nbin=600)
                )
age_fitt = plot_bins2(df_age_fitt,xlab="Age (year)",ylab="Hypertension",is_facet=F) 

#BMI
df_bmi_fit =list("Linear"=make_bins(x=subSet$BMXBMI,y=lm_logit$fitted.values,nbin=600),
                "Spline"=make_bins(x=subSet$BMXBMI,y=ns_logit$fitted.values,nbin=600),
                "Binned Data"=make_bins(x=subSet$BMXBMI,y=as.numeric(subSet$hypertension),nbin=600)
                )

bmi_fit <- plot_bins2(df_bmi_fit,xlab="BMI",ylab="Hypertension",is_facet=F) 

```
The following plots show binned Hypertension data; each bin contains about 600 data points and we compute the proportion of the participants who reported hypertension. 
Linear and Spline present the fitted values (probabilities) from the GLM with linear terms and apply the natural spline function on continuous terms of the participants who have 
hypertension. For both age, panel a), and BMI, panel b),  the GLM model using splines agrees with the estimates obtained by binning, while when these terms are modeled using
a simple linear term there are more substantial discrepancies. 

To compute the model estimates for each bin we simply average the computed fitted values (which are defined to be back-transformed to probabilities for logistic regression) over the 
same individuals in each bin. One might want to examine the relationship on the logit scale, which is easily done.

```{r qa_qc_plot, echo=TRUE,warning=FALSE,message=FALSE, fig.width = 12,fig.height=6}

ggpubr::ggarrange(age_fitt,bmi_fit,nrow = 1,ncol = 2,labels = c('a)','b)'))
```


## 4. Their findings
As the authors pointed out, the blood cobalt concentrations are not associated with the risk of hypertension based on the following summary table. The cobalt concentration does not significantly impact hypertension.
FIXME: but they have a bunch of other features in their table 2 - and it would be good if we can start to look at them.

```{r model1,warning=FALSE,message=FALSE}
subSet2 = base_df[, c("hypertension","RIDAGEYR", "RIAGENDR", "BMXBMI","DMDEDUC2", "RIDRETH1", "LBXBCO")]
subSet2 = na.omit(subSet2)

lm_logit <- glm(hypertension ~ RIDAGEYR + RIAGENDR + BMXBMI+DMDEDUC2+RIDRETH1+LBXBCO, data = subSet2, family = "binomial")
ns_logit <- glm(hypertension ~ ns(RIDAGEYR,df=7)+RIAGENDR + ns(BMXBMI,df=7) + DMDEDUC2 + RIDRETH1+LBXBCO, 
                   data = subSet2, family = "binomial",na.action=na.omit)

sjPlot::tab_model(lm_logit,ns_logit,
                  dv.labels = c("lm", "spline"),
                  show.ci = FALSE,show.stat = TRUE,show.se = TRUE,p.style = "scientific", digits.p = 2)

```
  FIXME:  This likely belongs in the QA/QC section.  The point of this code is to show the reader how they can estimate the functional form of the spline that they are fitting
to the data.  To do that, we pick a covariate, say Age, where we want to compute the spline.  Then we pick a set of Age values that cover the range of ages in the model.  
To get predictions from the model for a specific age we also need to specify values for all the other covariates in the model.  
Our suggestion is that for categorical variables choose the most common category and for continuous variables use the median value.

*** Robert, you only keep one base model in the end, do you want to me plot or compare somethings***
FIXME: yes the point here is to develop a better summary of the comparison of models with spline terms. I really don't like the R output that shows each term individually, as you can't really interpret them and they take up a lot of room.  I think we should instead, create one line for each spline term, and in it only put the value of the LRT comparing the model with the spline to the model without it.  From that comparison you can get the chi-squared statistic, the p-value and the df and those could be put into the table.  I think that would be a better thing.


```{r model2,warning=FALSE,message=FALSE}
   # base_logit <- glm(hypertension ~ RIDAGEYR + RIAGENDR + BMXBMI+DMDEDUC2+RIDRETH1 + sqrt(LBXBCO), data = data, family = "binomial")
   # base_logit <- glm(hypertension ~ ns(RIDAGEYR,df=7) + RIAGENDR + ns(BMXBMI,df=7) + DMDEDUC2 + RIDRETH1 + ns(sqrt(LBXBCO), df=7) + years, data = data, family = "binomial")
   base_logit <- glm(hypertension ~ ns(RIDAGEYR,df=7) + RIAGENDR + ns(BMXBMI,df=7) + DMDEDUC2 + RIDRETH1, data = base_df, family = "binomial")

   ## try to do some prediction - and then get a plot of the age spline
  ##46 of these
  yvals = seq(40,85,by=1)
  dfimpute = data.frame(RIDAGEYR=yvals, RIAGENDR=rep("Male", 46), BMXBMI=rep(28.9, 46), DMDEDUC2=rep("HS", 46), RIDRETH1=rep("Non-Hispanic White", 46))

  predV = predict(base_logit, newdata=dfimpute)
  # lines(40:85, predV)
  qplot(40:85,predV,geom = "line") + theme_bw()

 ##now look at BMI
  yBMI = 14:80
  dfBMIimpute = data.frame(RIDAGEYR=rep(60,67) , RIAGENDR=rep("Male", 67), BMXBMI=yBMI, DMDEDUC2=rep("HS", 67), RIDRETH1=rep("Non-Hispanic White", 67))
  predBMI = predict(base_logit, newdata=dfBMIimpute)
  qplot(14:80,predBMI,geom = "line") + theme_bw()
```
